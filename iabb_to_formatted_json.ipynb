{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/anaconda/lib/python2.7/site-packages\")\n",
    "import pandas as pd\n",
    "import shapefile \n",
    "import json\n",
    "import os\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to get neighborhoods from lat/long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#################################################################################################\n",
    "####### Inputs:\n",
    "#######     - path to shapefile\n",
    "#######\t\t- name of the attribute we want as our name of each region\n",
    "####### Returns:\n",
    "#######\t\t- dict mapping region names to shape polygons \n",
    "\n",
    "def generate_regions_to_points_dict(shapefile_path, region_attribute_name):\n",
    "    sf = shapefile.Reader(shapefile_path)\n",
    "    shapes = sf.shapes()\n",
    "    records = sf.records()\n",
    "    fields = sf.fields\n",
    "    \n",
    "    # Make sure region_attribute_name exists in the shapefile\n",
    "    found = False\n",
    "    for i in range(1, len(fields)):\n",
    "        if fields[i][0] == region_attribute_name:\n",
    "            attribute_key = i-1\n",
    "            found = True\n",
    "    if not found:\n",
    "        print \"Region attribute not found. Available attributes:\"\n",
    "        for i in range(1, len(fields)):\n",
    "            print str(fields[i][0]) + \"\\t\",\n",
    "        return     \n",
    "\n",
    "    \n",
    "    regions_to_points_dict = {}\n",
    "    for i in range(len(records)):\n",
    "        regions_to_points_dict[records[i][attribute_key]] = shapes[i].points\n",
    "    return regions_to_points_dict\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "#################################################################################################\n",
    "####### Code from: http://www.ariel.com.au/a/python-point-int-poly.html\n",
    "####### Inputs:\n",
    "####### \t- x value\n",
    "#######\t\t- y value\n",
    "#######\t\t- polygon: list of (x,y) pairs corresponding to the perimeter/corners of a polygon\n",
    "####### Returns: true if x,y is in the specified polygon\n",
    "\n",
    "def point_inside_polygon(x,y,poly):\n",
    "\n",
    "    n = len(poly)\n",
    "    inside =False\n",
    "\n",
    "    p1x,p1y = poly[0]\n",
    "    for i in range(n+1):\n",
    "        p2x,p2y = poly[i % n]\n",
    "        if y > min(p1y,p2y):\n",
    "            if y <= max(p1y,p2y):\n",
    "                if x <= max(p1x,p2x):\n",
    "                    if p1y != p2y:\n",
    "                        xinters = (y-p1y)*(p2x-p1x)/(p2y-p1y)+p1x\n",
    "                    if p1x == p2x or x <= xinters:\n",
    "                        inside = not inside\n",
    "        p1x,p1y = p2x,p2y\n",
    "\n",
    "    return inside\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################################\n",
    "####### Inputs:\n",
    "#######     - latitude\n",
    "#######\t\t- longitude \n",
    "#######     - regions_to_points_dict - keys are region names, values are lists of points outlining the region\n",
    "#######\t\t\t\t\t\t\t\t- see \"generate_regions_to_points_dict\" method to create one of these dicts\n",
    "####### Returns:\n",
    "#######\t\t- region the latitude,longitude input falls inside \n",
    "\n",
    "def get_region_from_latlong_and_shapefile(latitude, longitude, regions_to_points_dict, print_errors=True):\n",
    "    for key in regions_to_points_dict.keys():\n",
    "        if point_inside_polygon(longitude, latitude, regions_to_points_dict[key]):\n",
    "            return key\n",
    "    if print_errors:\n",
    "        print \"region not found\"\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data and format columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate mapping for lat/long to neighborhoods\n",
    "path_to_shape_file = '/Users/nbw/Desktop/cs171_test_files/ZillowNeighborhoods-NY/ZillowNeighborhoods-NY'\n",
    "neighborhood_dict = generate_regions_to_points_dict(path_to_shape_file, 'NAME')\n",
    "    \n",
    "# generate mapping from neighborhoods to boroughs\n",
    "sf = shapefile.Reader(path_to_shape_file)\n",
    "records = sf.records()\n",
    "\n",
    "boroughs_list =  [\"New York City-Manhattan\", \"New York City-Brooklyn\", \"New York City-Queens\", \"New York City-Bronx\", \"New York City-Staten Island\"]\n",
    "\n",
    "boroughs_list =  [\"New York City-Manhattan\", \"New York City-Brooklyn\", \"New York City-Queens\", \"New York City-Bronx\", \"New York City-Staten Island\"]\n",
    "neighborhood_to_borough_dict = {}\n",
    "for record in records:\n",
    "    if record[2] in boroughs_list:\n",
    "        neighborhood_to_borough_dict[record[3]] = record[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_datafiles = \"/Users/nbw/Dropbox/CS_171_data/Airbnb Files/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2705: DtypeWarning: Columns (26,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a7a97ae7b673>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"neighborhood\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neighborhood'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_region_from_latlong_and_shapefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'latitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'longitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mneighborhood_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# fill missing values using sklearn's knn functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-25bbb74ebb25>\u001b[0m in \u001b[0;36mget_region_from_latlong_and_shapefile\u001b[0;34m(latitude, longitude, regions_to_points_dict, print_errors)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_region_from_latlong_and_shapefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlongitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregions_to_points_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mregions_to_points_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mpoint_inside_polygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlongitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregions_to_points_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprint_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-25bbb74ebb25>\u001b[0m in \u001b[0;36mpoint_inside_polygon\u001b[0;34m(x, y, poly)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mp2x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp2y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp2y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp2y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp2x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for filename in os.listdir(path_to_datafiles):\n",
    "    counter += 1\n",
    "    print counter \n",
    "    \n",
    "    # make sure file is right format\n",
    "    if \"NYC_listings\" not in filename or \"ts.csv\" in filename or filename==\"2015-01-01_NYC_listings.csv\":\n",
    "        continue\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filename = '2015-03-01_NYC_listings.csv'\n",
    "df = pd.read_csv(path_to_datafiles + \"2015-03-01_NYC_listings.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# rename columns to match standardized names\n",
    "df.rename(columns={'id': 'room_id', 'number_of_reviews': 'num_reviews', \\\n",
    "        'minimum_nights': 'min_stay', 'last_scraped': 'collected'}, inplace=True)\n",
    "\n",
    "# convert iabb's price from \"$__\" strings to floats\n",
    "df['price'] = df['price'].apply(lambda x: float(x.split(\"$\")[1].replace(\",\", \"\")))\n",
    "\n",
    "# calculate ratings from composite values\n",
    "df[\"rating\"] = None\n",
    "for i in df.index.values:\n",
    "    if df['review_scores_accuracy'].iloc[i] == df['review_scores_accuracy'].iloc[i]:\n",
    "        scores_sum = df['review_scores_accuracy'].iloc[i] + df['review_scores_cleanliness'].iloc[i] + \\\n",
    "        df['review_scores_checkin'].iloc[i] + df['review_scores_communication'].iloc[i] + \\\n",
    "        df['review_scores_location'].iloc[i] + df['review_scores_value'].iloc[i]  \n",
    "        df.set_value(i, \"rating\", scores_sum/12.0)\n",
    "\n",
    "# drop unwanted columns\n",
    "cols_to_keep = [u'room_id', u'collected', u'host_id', u'latitude', u'longitude', u'room_type', u'accommodates', \\\n",
    "u'bathrooms', u'bedrooms', u'price', u'min_stay', u'num_reviews', u'calculated_host_listings_count', u'rating', u'source', \\\n",
    "u'illegal', u'taxes', u'date', u'property_type', u'host_location', u'reviews_per_month', u'maximum_nights']\n",
    "df = df.drop(list(set(df.columns) - set(cols_to_keep)), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "df[\"neighborhood\"] = None\n",
    "for i in df.index.values:\n",
    "    df.set_value(i, 'neighborhood', get_region_from_latlong_and_shapefile(df['latitude'].iloc[i] , df['longitude'].iloc[i] , neighborhood_dict, print_errors=False))\n",
    "\n",
    "# fill missing values using sklearn's knn functions\n",
    "unknown = df[df[\"neighborhood\"] != df[\"neighborhood\"]]\n",
    "known = df[df[\"neighborhood\"] == df[\"neighborhood\"]]\n",
    "\n",
    "train_x_matrix = known[[\"latitude\", \"longitude\"]].values\n",
    "train_y_matrix = known[\"neighborhood\"]\n",
    "test_x_matrix = unknown[[\"latitude\", \"longitude\"]].values\n",
    "\n",
    "model = KNN(n_neighbors = 1)\n",
    "model.fit(train_x_matrix, train_y_matrix)\n",
    "preds = model.predict(test_x_matrix)\n",
    "\n",
    "unknown[\"neighborhood\"] = preds\n",
    "\n",
    "df.loc[unknown.index, 'neighborhood'] = pd.Series(unknown[\"neighborhood\"])\n",
    "\n",
    "# get boroughs from neighborhood\n",
    "df[\"borough\"] = None\n",
    "for i in df.index.values:\n",
    "    if df['neighborhood'].iloc[i]:\n",
    "        df.set_value(i, 'borough', neighborhood_to_borough_dict[df['neighborhood'].iloc[i]])\n",
    "\n",
    "df['borough'] = df['borough'].apply(lambda x: x.split(\"-\")[1] if x else None)\n",
    "\n",
    "# add identifier columns\n",
    "df[\"date\"] = filename.split(\"_\")[0]\n",
    "df[\"source\"] = \"iabb\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CALCULATE TAXES\n",
    "\n",
    "df[\"tax_total\"] = 0\n",
    "df[\"tax_NYC_sales\"] = 0\n",
    "df[\"tax_state_sales\"] = 0\n",
    "df[\"tax_mctd\"] = 0\n",
    "df[\"tax_hotel_occupancy\"] = 0\n",
    "df[\"tax_javits\"] = 0\n",
    "\n",
    "df[\"illegal\"] = 0\n",
    "\n",
    "avgLength = 6.4;\n",
    "maxNights = 30 * .7;\n",
    "\n",
    "for i in df.index.values:\n",
    "\n",
    "    stayLength = max(df['min_stay'].iloc[i], avgLength)\n",
    "    revs = df['reviews_per_month'].iloc[i]\n",
    "    if revs==revs:\n",
    "        nights_booked = min(revs * 2 * stayLength, maxNights)\n",
    "    else:\n",
    "        nights_booked = 0\n",
    "\n",
    "\n",
    "    month_revenue = nights_booked * df['price'].iloc[i];\n",
    "\n",
    "    hotel_tax_applies = (df['maximum_nights'].iloc[i] > 14)\n",
    "\n",
    "    bedrooms = df['bedrooms'].iloc[i]\n",
    "    if df['room_type'].iloc[i] == \"Entire home/apt\" and bedrooms==bedrooms:\n",
    "        num_rooms = bedrooms + 1\n",
    "    elif bedrooms==bedrooms:\n",
    "        num_rooms = bedrooms\n",
    "    else:\n",
    "        num_rooms = 1\n",
    "\n",
    "    tax_NYC_sales = .045 * month_revenue;\n",
    "    tax_state_sales = .04 * month_revenue;\n",
    "    tax_mctd = .00375 * month_revenue;\n",
    "    if hotel_tax_applies: \n",
    "        tax_hotel_occupancy = .05875 * month_revenue + 2 * num_rooms * nights_booked\n",
    "        tax_javits = 1.5 * num_rooms * nights_booked\n",
    "    else:\n",
    "        tax_hotel_occupancy = 0\n",
    "        tax_javits = 0\n",
    "    tax_total = tax_NYC_sales + tax_state_sales + tax_mctd + tax_hotel_occupancy + tax_javits\n",
    "    \n",
    "    df.set_value(i, \"tax_total\", tax_total)\n",
    "    df.set_value(i, \"tax_NYC_sales\", tax_NYC_sales)\n",
    "    df.set_value(i, \"tax_state_sales\", tax_state_sales)\n",
    "    df.set_value(i, \"tax_mctd\", tax_mctd)\n",
    "    df.set_value(i, \"tax_hotel_occupancy\", tax_hotel_occupancy)\n",
    "    df.set_value(i, \"tax_javits\", tax_javits)\n",
    "    \n",
    "    host_loc = df['host_location'].iloc[i]\n",
    "    if host_loc != host_loc: \n",
    "        if (df['property_type'].iloc[i] == \"Apartment\") and (df['min_stay'].iloc[i] < 30) and (df['room_type'].iloc[i] == \"Entire home/apt\" or df[\"calculated_host_listings_count\"].iloc[i] > 1):\n",
    "            df.set_value(i, \"illegal\", 1)\n",
    "    else:\n",
    "        if (df['property_type'].iloc[i] == \"Apartment\") and (df['min_stay'].iloc[i] < 30) and (df['room_type'].iloc[i] == \"Entire home/apt\" or df[\"calculated_host_listings_count\"].iloc[i] > 1 or (not \"New York\" in host_loc and not \"NY\" in host_loc and host_loc != \"US\")):\n",
    "            df.set_value(i, \"illegal\", 1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.drop([u'host_location', u'maximum_nights', u'calculated_host_listings_count', u'reviews_per_month'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent illegal:  0.672964097266\n",
      "Taxes for this month:\n",
      "NYC_sales:  1386884\n",
      "state_sales:  1232271\n",
      "mctd:  106629\n",
      "hotel_occupancy:  2293746\n",
      "javits:  483836\n",
      "total: 5537476\n"
     ]
    }
   ],
   "source": [
    "print \"Percent illegal: \" , sum(df[\"illegal\"])/float(len(df))\n",
    "print \"Taxes for this month:\"\n",
    "print \"NYC_sales: \" , sum(df[\"tax_NYC_sales\"]) \n",
    "print \"state_sales: \" , sum(df[\"tax_state_sales\"]) \n",
    "print \"mctd: \" , sum(df[\"tax_mctd\"]) \n",
    "print \"hotel_occupancy: \" , sum(df[\"tax_hotel_occupancy\"]) \n",
    "print \"javits: \" , sum(df[\"tax_javits\"]) \n",
    "print \"total:\" , sum(df[\"tax_total\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-03-01.json written\n"
     ]
    }
   ],
   "source": [
    "# convert df to json array and write to file\n",
    "json_array = df.to_json(orient='records')\n",
    "\n",
    "with open(filename.split(\"_\")[0] + \"_with_analyses.json\", 'w') as f:\n",
    "#with open(\"jsondata/\"+filename.split(\"_\")[0] + \".json\", 'w') as f:\n",
    "    f.write(json_array)\n",
    "print filename.split(\"_\")[0] + \".json written\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
